"""
================================================================================
MÃ“DULO DE ANÃLISIS DE DATOS CON PANDAS
================================================================================
Universidad Nacional de Chimborazo
Facultad de IngenierÃ­a - Ciencia de Datos e Inteligencia Artificial
Asignatura: Estructura de Datos

Este mÃ³dulo implementa funciones de anÃ¡lisis exploratorio de datos (EDA)
utilizando la librerÃ­a Pandas para el dataset de placas vehiculares.

JUSTIFICACIÃ“N DEL USO DE PANDAS:
- Eficiencia en manipulaciÃ³n de datos tabulares
- Funciones optimizadas para agregaciÃ³n y estadÃ­sticas
- IntegraciÃ³n nativa con visualizaciÃ³n (matplotlib)
- Manejo elegante de datos faltantes y tipos de datos

Autores: Juan David Ruiz Jara, Ian Nolivos, KlÃ©ver Castillo, 
         Estefany Condor, Natasha NuÃ±ez, Elmer Rivadeneira
================================================================================
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional
from datetime import datetime

from app.exceptions import TransformError


# ============================================================================
# FUNCIONES DE ANÃLISIS EXPLORATORIO
# ============================================================================

def get_dataset_summary(df: pd.DataFrame) -> Dict:
    """
    Genera un resumen completo del dataset.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - df.shape: Obtener dimensiones de forma eficiente
    - df.dtypes: InspecciÃ³n de tipos de datos
    - df.isna().sum(): Conteo vectorizado de nulos
    - df.nunique(): Conteo de valores Ãºnicos optimizado
    
    Args:
        df (pd.DataFrame): DataFrame a analizar
        
    Returns:
        Dict: Diccionario con el resumen del dataset
    """
    summary = {
        'filas': len(df),
        'columnas': len(df.columns),
        'columnas_lista': list(df.columns),
        'tipos_datos': df.dtypes.to_dict(),
        'valores_nulos': df.isna().sum().to_dict(),
        'total_nulos': df.isna().sum().sum(),
        'valores_unicos': df.nunique().to_dict(),
        'memoria_uso_mb': df.memory_usage(deep=True).sum() / (1024 * 1024)
    }
    
    return summary


def analyze_estados_ant(df: pd.DataFrame) -> pd.DataFrame:
    """
    Analiza la distribuciÃ³n de estados ANT en el dataset.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - value_counts(): Conteo eficiente de frecuencias
    - Operaciones vectorizadas para cÃ¡lculo de porcentajes
    - reset_index(): ConversiÃ³n a DataFrame estructurado
    
    Args:
        df (pd.DataFrame): DataFrame con columna 'estado_ANT'
        
    Returns:
        pd.DataFrame: Tabla de frecuencias y porcentajes por estado
        
    Example:
        >>> analysis = analyze_estados_ant(df)
        >>> print(analysis)
        
           estado_ANT  cantidad  porcentaje
        0  Habilitada       902       90.20
        1  Suspendida        55        5.50
        2   Bloqueada        43        4.30
    """
    print("ğŸ“Š Analizando distribuciÃ³n de estados ANT...")
    
    # Usar value_counts() de Pandas - muy eficiente para conteos
    counts = df['estado_ANT'].value_counts()
    percentages = df['estado_ANT'].value_counts(normalize=True) * 100
    
    # Crear DataFrame de anÃ¡lisis
    analysis = pd.DataFrame({
        'estado_ANT': counts.index,
        'cantidad': counts.values,
        'porcentaje': percentages.values.round(2)
    })
    
    print(f"âœ… AnÃ¡lisis completado: {len(analysis)} estados encontrados")
    
    return analysis


def analyze_trafico_por_ubicacion(df: pd.DataFrame) -> pd.DataFrame:
    """
    Analiza el volumen de trÃ¡fico por ubicaciÃ³n de cÃ¡mara y peaje.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - groupby(): AgrupaciÃ³n eficiente de datos
    - agg(): Agregaciones mÃºltiples en una sola operaciÃ³n
    - sort_values(): Ordenamiento optimizado
    
    Args:
        df (pd.DataFrame): DataFrame con columnas 'ubicacion_camara' y 'peaje_ciudad'
        
    Returns:
        pd.DataFrame: AnÃ¡lisis de trÃ¡fico por ubicaciÃ³n
    """
    print("ğŸ“Š Analizando trÃ¡fico por ubicaciÃ³n...")
    
    # Usar groupby de Pandas para agregaciÃ³n eficiente
    trafico = df.groupby(['ubicacion_camara', 'peaje_ciudad']).agg(
        registros=('id', 'count'),
        placas_unicas=('placa', 'nunique'),
        primera_fecha=('fecha_registro', 'min'),
        ultima_fecha=('fecha_registro', 'max')
    ).reset_index()
    
    # Ordenar por nÃºmero de registros (descendente)
    trafico = trafico.sort_values('registros', ascending=False)
    
    print(f"âœ… AnÃ¡lisis completado: {len(trafico)} combinaciones ubicaciÃ³n-peaje")
    
    return trafico


def analyze_temporal(df: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """
    Realiza anÃ¡lisis temporal del dataset.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - dt accessor: ExtracciÃ³n eficiente de componentes de fecha
    - groupby + size(): Conteo rÃ¡pido por grupos
    - Soporte nativo para series temporales
    
    Args:
        df (pd.DataFrame): DataFrame con columna 'fecha_registro'
        
    Returns:
        Dict con DataFrames de anÃ¡lisis temporal:
        - 'por_aÃ±o': Registros por aÃ±o
        - 'por_mes': Registros por mes
        - 'por_hora': Registros por hora del dÃ­a
        - 'por_dia_semana': Registros por dÃ­a de la semana
    """
    print("ğŸ“Š Realizando anÃ¡lisis temporal...")
    
    # Asegurar que fecha_registro es datetime
    if not pd.api.types.is_datetime64_any_dtype(df['fecha_registro']):
        df = df.copy()
        df['fecha_registro'] = pd.to_datetime(df['fecha_registro'])
    
    # AnÃ¡lisis por aÃ±o
    por_aÃ±o = df.groupby(df['fecha_registro'].dt.year).size().reset_index()
    por_aÃ±o.columns = ['aÃ±o', 'registros']
    
    # AnÃ¡lisis por mes (1-12)
    por_mes = df.groupby(df['fecha_registro'].dt.month).size().reset_index()
    por_mes.columns = ['mes', 'registros']
    
    # AnÃ¡lisis por hora del dÃ­a (0-23)
    por_hora = df.groupby(df['fecha_registro'].dt.hour).size().reset_index()
    por_hora.columns = ['hora', 'registros']
    
    # AnÃ¡lisis por dÃ­a de la semana
    por_dia_semana = df.groupby(df['fecha_registro'].dt.day_name()).size().reset_index()
    por_dia_semana.columns = ['dia_semana', 'registros']
    
    # Ordenar dÃ­as de la semana correctamente
    dias_orden = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    por_dia_semana['dia_orden'] = por_dia_semana['dia_semana'].map(
        {day: i for i, day in enumerate(dias_orden)}
    )
    por_dia_semana = por_dia_semana.sort_values('dia_orden').drop('dia_orden', axis=1)
    
    print(f"âœ… AnÃ¡lisis temporal completado")
    
    return {
        'por_aÃ±o': por_aÃ±o,
        'por_mes': por_mes,
        'por_hora': por_hora,
        'por_dia_semana': por_dia_semana
    }


def analyze_frecuencia_placas(df: pd.DataFrame) -> Tuple[pd.DataFrame, Dict]:
    """
    Analiza la frecuencia de apariciÃ³n de cada placa.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - value_counts(): Conteo ultra-eficiente de frecuencias
    - describe(): EstadÃ­sticas descriptivas automÃ¡ticas
    - IndexaciÃ³n booleana para filtrado
    
    Args:
        df (pd.DataFrame): DataFrame con columna 'placa'
        
    Returns:
        Tuple[pd.DataFrame, Dict]: 
        - DataFrame con frecuencia por placa
        - Diccionario con estadÃ­sticas de frecuencia
    """
    print("ğŸ“Š Analizando frecuencia de placas...")
    
    # Contar frecuencia de cada placa
    frecuencia = df['placa'].value_counts().reset_index()
    frecuencia.columns = ['placa', 'num_registros']
    
    # Calcular estadÃ­sticas
    stats = {
        'total_placas_unicas': len(frecuencia),
        'promedio_registros': frecuencia['num_registros'].mean(),
        'mediana_registros': frecuencia['num_registros'].median(),
        'max_registros': frecuencia['num_registros'].max(),
        'min_registros': frecuencia['num_registros'].min(),
        'placas_con_un_registro': (frecuencia['num_registros'] == 1).sum(),
        'placas_con_multiples': (frecuencia['num_registros'] > 1).sum()
    }
    
    print(f"âœ… AnÃ¡lisis completado: {stats['total_placas_unicas']} placas Ãºnicas")
    
    return frecuencia, stats


def identify_alertas(df: pd.DataFrame) -> Dict:
    """
    Identifica vehÃ­culos con estados problemÃ¡ticos (alertas).
    
    JUSTIFICACIÃ“N DE PANDAS:
    - isin(): Filtrado eficiente por mÃºltiples valores
    - groupby().agg(): Agregaciones complejas en una operaciÃ³n
    - Manejo elegante de datos categÃ³ricos
    
    Args:
        df (pd.DataFrame): DataFrame con columna 'estado_ANT'
        
    Returns:
        Dict con informaciÃ³n de alertas:
        - 'total_alertas': NÃºmero total de registros con alerta
        - 'por_estado': Conteo por tipo de alerta
        - 'placas_alertas': Lista de placas con alertas
        - 'detalle': DataFrame con detalle de alertas
    """
    print("ğŸš¨ Identificando vehÃ­culos con alertas...")
    
    # Filtrar estados problemÃ¡ticos
    alertas_df = df[df['estado_ANT'].isin(['Bloqueada', 'Suspendida'])].copy()
    
    # Conteo por estado
    por_estado = alertas_df['estado_ANT'].value_counts().to_dict()
    
    # Placas Ãºnicas con alertas
    placas_con_alertas = alertas_df['placa'].unique().tolist()
    
    # Detalle de alertas por placa
    detalle = alertas_df.groupby(['placa', 'estado_ANT']).agg(
        num_detecciones=('id', 'count'),
        primera_deteccion=('fecha_registro', 'min'),
        ultima_deteccion=('fecha_registro', 'max'),
        ubicaciones=('ubicacion_camara', lambda x: ', '.join(x.unique()))
    ).reset_index().sort_values('num_detecciones', ascending=False)
    
    result = {
        'total_alertas': len(alertas_df),
        'por_estado': por_estado,
        'placas_con_alertas': len(placas_con_alertas),
        'lista_placas': placas_con_alertas,
        'detalle': detalle
    }
    
    print(f"âœ… Alertas identificadas: {result['total_alertas']} registros, "
          f"{result['placas_con_alertas']} placas Ãºnicas")
    
    return result


def create_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    Crea nuevas variables (feature engineering) para el dataset.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - Operaciones vectorizadas para creaciÃ³n de columnas
    - dt accessor para extracciÃ³n de componentes temporales
    - str accessor para manipulaciÃ³n de strings
    
    Nuevas variables creadas:
    - aÃ±o, mes, dia, hora: Componentes de fecha
    - dia_semana: Nombre del dÃ­a
    - es_fin_semana: Indicador booleano
    - placa_provincia: CÃ³digo de provincia (primera letra)
    - placa_sin_guion: Placa normalizada para ordenamiento
    
    Args:
        df (pd.DataFrame): DataFrame original
        
    Returns:
        pd.DataFrame: DataFrame con nuevas variables
    """
    print("ğŸ”§ Creando nuevas variables (feature engineering)...")
    
    df_copy = df.copy()
    
    try:
        # Asegurar que fecha_registro es datetime
        if not pd.api.types.is_datetime64_any_dtype(df_copy['fecha_registro']):
            df_copy['fecha_registro'] = pd.to_datetime(df_copy['fecha_registro'])
        
        # Variables temporales usando el accessor .dt de Pandas
        df_copy['aÃ±o'] = df_copy['fecha_registro'].dt.year
        df_copy['mes'] = df_copy['fecha_registro'].dt.month
        df_copy['dia'] = df_copy['fecha_registro'].dt.day
        df_copy['hora'] = df_copy['fecha_registro'].dt.hour
        df_copy['dia_semana'] = df_copy['fecha_registro'].dt.day_name()
        
        # Indicador de fin de semana
        df_copy['es_fin_semana'] = df_copy['fecha_registro'].dt.dayofweek >= 5
        
        # Extraer cÃ³digo de provincia de la placa (primera letra)
        # En Ecuador, la primera letra indica la provincia
        df_copy['placa_provincia'] = df_copy['placa'].str[0]
        
        # Placa normalizada (sin guiÃ³n, mayÃºsculas) para ordenamiento
        df_copy['placa_sin_guion'] = df_copy['placa'].str.replace('-', '').str.upper()
        
        # Indicador de alerta
        df_copy['tiene_alerta'] = df_copy['estado_ANT'].isin(['Bloqueada', 'Suspendida'])
        
        print(f"âœ… Variables creadas: aÃ±o, mes, dia, hora, dia_semana, es_fin_semana, "
              f"placa_provincia, placa_sin_guion, tiene_alerta")
        
        return df_copy
        
    except Exception as e:
        raise TransformError(
            "Error al crear nuevas variables",
            transform_type="feature_engineering",
            original_error=e
        )


def generate_statistics_table(df: pd.DataFrame) -> pd.DataFrame:
    """
    Genera una tabla de estadÃ­sticas descriptivas para el dataset.
    
    JUSTIFICACIÃ“N DE PANDAS:
    - describe(): EstadÃ­sticas descriptivas automÃ¡ticas
    - Operaciones de agregaciÃ³n mÃºltiple
    - Formateo flexible de salida
    
    Args:
        df (pd.DataFrame): DataFrame a analizar
        
    Returns:
        pd.DataFrame: Tabla de estadÃ­sticas
    """
    # EstadÃ­sticas para columnas numÃ©ricas
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    if numeric_cols:
        stats = df[numeric_cols].describe()
        return stats.T  # Transponer para mejor lectura
    else:
        return pd.DataFrame()


if __name__ == "__main__":
    # Pruebas del mÃ³dulo
    print("=" * 60)
    print("PRUEBAS DEL MÃ“DULO DE ANÃLISIS")
    print("=" * 60)
    
    # Crear DataFrame de prueba
    np.random.seed(42)
    n = 100
    
    df_test = pd.DataFrame({
        'id': range(1, n + 1),
        'placa': [f"{'ABC'[i%3]}{chr(65+i%26)}{chr(65+(i+1)%26)}-{1000+i}" for i in range(n)],
        'fecha_registro': pd.date_range(start='2024-01-01', periods=n, freq='H'),
        'estado_ANT': np.random.choice(['Habilitada', 'Suspendida', 'Bloqueada'], n, p=[0.9, 0.06, 0.04]),
        'ubicacion_camara': np.random.choice(['Quito', 'Guayaquil', 'Cuenca'], n),
        'peaje_ciudad': np.random.choice(['Peaje A', 'Peaje B', 'Peaje C'], n)
    })
    
    print("\nğŸ“Œ DataFrame de prueba creado")
    print(f"   Filas: {len(df_test)}, Columnas: {len(df_test.columns)}")
    
    # Prueba 1: Resumen del dataset
    print("\nğŸ“Œ Prueba 1: Resumen del dataset")
    summary = get_dataset_summary(df_test)
    print(f"   Filas: {summary['filas']}, Columnas: {summary['columnas']}")
    
    # Prueba 2: AnÃ¡lisis de estados
    print("\nğŸ“Œ Prueba 2: AnÃ¡lisis de estados ANT")
    estados = analyze_estados_ant(df_test)
    print(estados)
    
    # Prueba 3: AnÃ¡lisis temporal
    print("\nğŸ“Œ Prueba 3: AnÃ¡lisis temporal")
    temporal = analyze_temporal(df_test)
    print(f"   Registros por hora: {len(temporal['por_hora'])} horas")
    
    # Prueba 4: Crear features
    print("\nğŸ“Œ Prueba 4: Feature engineering")
    df_features = create_features(df_test)
    print(f"   Nuevas columnas: {[c for c in df_features.columns if c not in df_test.columns]}")
    
    # Prueba 5: Identificar alertas
    print("\nğŸ“Œ Prueba 5: Identificar alertas")
    alertas = identify_alertas(df_test)
    print(f"   Total alertas: {alertas['total_alertas']}")
    
    print("\nâœ… Todas las pruebas completadas")
